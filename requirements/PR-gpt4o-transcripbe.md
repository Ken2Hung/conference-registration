# PRï¼šStreamlitï¼ˆéº¥å…‹é¢¨å³æ™‚ï¼‰ï¼‹ OpenAI **gpt-4o-mini-transcribe** é€å­—ç¨¿
**ä¸éœ€ä¸Šå‚³æª”æ¡ˆ**ï¼›æŒ‰ä¸‹ã€Œé–‹å§‹è½‰éŒ„ã€å¾Œï¼Œç€è¦½å™¨å³æˆæ¬Šéº¥å…‹é¢¨ï¼Œå°‡èªéŸ³ä»¥**å°ç‰‡æ®µï¼ˆé è¨­ 2 ç§’ï¼‰**ä¸²æµå› Pythonï¼Œå¾Œç«¯æŠŠç‰‡æ®µé€åˆ° **`audio.transcriptions`**ï¼ˆæ¨¡å‹ï¼š`gpt-4o-mini-transcribe`ï¼‰ä¸¦å³æ™‚æŠŠæ–‡å­—é¡¯ç¤ºåœ¨å‰ç«¯ã€‚

> ç‚ºäº†ç¶­æŒä½ æŒ‡å®šçš„ **`gpt-4o-mini-transcribe`**ï¼ˆé Realtime æ¨¡å‹ï¼‰ï¼Œæœ¬å¯¦ä½œæ¡ç”¨ã€Œ**ç€è¦½å™¨éŒ„éŸ³ â†’ å°ç‰‡æ®µä¸Šå‚³ â†’ æŒçºŒè½‰éŒ„**ã€çš„æ–¹å¼é”åˆ°æº–å³æ™‚ã€‚å®˜æ–¹ Audio API æ˜ç¢ºæ”¯æ´ `gpt-4o(-mini)-transcribe` åœ¨ **/audio/transcriptions** ç«¯é»ä½¿ç”¨ã€‚îˆ€citeîˆ‚turn0search7îˆ  
> è‹¥ä½ æœªä¾†æƒ³åšåˆ°æ›´ä½å»¶é²æˆ–é›™å‘èªéŸ³ï¼Œå‰‡å¯æ”¹ç”¨ **Realtime APIï¼ˆWebRTC/WebSocketï¼‰** èˆ‡ `gpt-realtime(-mini)`ã€‚æœ¬æ–‡åœ¨æœ€å¾Œé™„ä¸Šæ›¿ä»£æ–¹æ¡ˆèˆ‡æˆæœ¬æ¯”è¼ƒã€‚îˆ€citeîˆ‚turn0search6îˆ‚turn0search11îˆ

---

## æ‘˜è¦ (Summary)
- âœ… **æŒ‰éˆ•ä¸€éµå•Ÿå‹•**ï¼šæŒ‰ä¸‹ã€Œé–‹å§‹è½‰éŒ„ã€å³å•Ÿç”¨éº¥å…‹é¢¨ã€é–‹å§‹åˆ†æ®µè½‰éŒ„ã€‚
- âœ… **å³æ™‚é¡¯ç¤º**ï¼šæ¯æ®µå®Œæˆå¾Œå°±è¿½åŠ åˆ°ç•«é¢æ–‡å­—å€ï¼Œæä¾› **.txt** ä¸‹è¼‰ã€‚
- âœ… **ä½è€¦åˆ**ï¼šè½‰éŒ„é‚è¼¯å°è£æ–¼ `transcriber.py`ï¼ŒUI åœ¨ `app.py`ã€‚  
- âœ… **ä¸éœ€ä¸Šå‚³æ•´æª”**ï¼šä½¿ç”¨è€…ç„¡é ˆå…ˆæº–å‚™åª’é«”æª”ã€‚  
- ğŸ”§ **å¯èª¿åƒæ•¸**ï¼šç‰‡æ®µé•·åº¦ï¼ˆé è¨­ 2 ç§’ï¼‰ã€ç°¡æ˜“ VAD é–€æª»ï¼ˆç¯€çœè²»ç”¨ï¼‰ã€‚
- ğŸ§© **æŠ€è¡“è¦é»**ï¼šç”¨ `streamlit-webrtc` å–å¾—ç€è¦½å™¨éº¥å…‹é¢¨ä¸¦æ–¼ Python å³æ™‚è™•ç†éŸ³è¨Šç‰‡æ®µã€‚îˆ€citeîˆ‚turn6view0îˆ

---

## æ¶æ§‹ (Architecture)

```
Browser (getUserMedia via streamlit-webrtc)
   â””â”€ éŸ³è¨Šå¹€ (48000Hz) â†’ Python éŸ³è¨Š callback
        â””â”€ ç´¯ç©è‡³ 2s PCM16 â†’ è½‰ .wav bytes
             â””â”€ OpenAI audio.transcriptions.create(model="gpt-4o-mini-transcribe")
                  â””â”€ ç´¯ç©çµæœè‡³ session_state â†’ UI å¯¦æ™‚è¿½åŠ å‘ˆç¾ â†’ å¯ä¸‹è¼‰ .txt
```

---

## æ–°å¢/è®Šæ›´æª”æ¡ˆ (Files Changed)

```
.
â”œâ”€ app.py                 # Streamlit ä¸»ç¨‹å¼ï¼ˆUIï¼‹webrtcï¼‹ç‹€æ…‹é¡¯ç¤º/ä¸‹è¼‰ï¼‰
â”œâ”€ transcriber.py         # OpenAI è½‰éŒ„å°è£ï¼ˆå‘¼å« audio.transcriptionsï¼‰
â”œâ”€ audio_chunker.py       # éŸ³è¨Šç‰‡æ®µåŒ–èˆ‡ç°¡æ˜“ VAD
â”œâ”€ requirements.txt       # ä¾è³´å¥—ä»¶
â”œâ”€ .env.example           # OPENAI_API_KEY / OPENAI_BASE_URL
â””â”€ PR-Streamlit-RT-Mic-gpt4o-mini-transcribe.md  # æœ¬æ–‡ä»¶
```
---
# PR æ›´æ–°ï¼šå³æ™‚éº¥å…‹é¢¨è½‰éŒ„ä¹‹**æŒä¹…åŒ–æ”¹ç‚ºå¯«å…¥ `./resource/*.txt` å¯¦é«”æª”**

æœ¬æ›´æ–°åœ¨å‰ä¸€ç‰ˆã€ŒStreamlit + gpt-4o-mini-transcribeï¼ˆéº¥å…‹é¢¨å³æ™‚ï¼‰ã€åŸºç¤ä¸Šï¼Œå°‡**æŒä¹…åŒ–ç­–ç•¥**ç”±åƒ…å­˜åœ¨è¨˜æ†¶é«”æ”¹ç‚ºï¼š
- è½‰éŒ„éç¨‹æœƒ**å³æ™‚ append** åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ **`resource/`** ç›®éŒ„å…§çš„ **`.txt`** æª”æ¡ˆã€‚
- æª”åå¯ç”±ä½¿ç”¨è€…è¼¸å…¥ï¼›è‹¥ç•™ç©ºå‰‡è‡ªå‹•ä»¥ `transcript-YYYYMMDD-HHMMSS.txt` ç”¢ç”Ÿã€‚
- `resource/` ç›®éŒ„è‹¥ä¸å­˜åœ¨æœƒè‡ªå‹•å»ºç«‹ã€‚
- ã€Œåœæ­¢ã€æŒ‰éˆ•æœƒåœ¨æª”å°¾å¯«å…¥ç°¡å–®çµæŸæ¨™è¨˜ï¼ˆæ™‚é–“ï¼‰ã€‚

> ä»ç¶­æŒï¼šä¸éœ€ä¸Šå‚³æ•´æª”ã€æŒ‰ä¸‹é–‹å§‹å³æ™‚è½‰éŒ„ã€é é¢åŒæ­¥é¡¯ç¤ºã€åŒæ™‚å¯ä¸‹è¼‰ç›®å‰å…§å®¹ç‚º .txtã€‚

---

## è®Šæ›´æ‘˜è¦

- âœ¨ æ–°å¢æª”åè¼¸å…¥æ¡†ï¼š`è¼¸å‡ºæª”åï¼ˆ.txtï¼Œè‡ªå‹•ç”Ÿæˆå¯ç•™ç©ºï¼‰`  
- âœ¨ æ–°å¢ `resource/` ç›®éŒ„è‡ªå‹•å»ºç«‹èˆ‡æª”æ¡ˆè·¯å¾‘ç®¡ç† `st.session_state.file_path`  
- âœ¨ èƒŒæ™¯è½‰éŒ„åŸ·è¡Œç·’æ¯ç”¢ç”Ÿä¸€æ®µæ–‡å­—ä¾¿**ç«‹å³å¯«å…¥**ç›®æ¨™æª”æ¡ˆï¼ˆUTF-8ï¼‰  
- âœ¨ ã€Œé–‹å§‹è½‰éŒ„ã€åœ¨æª”é ­å¯«å…¥èµ·å§‹æ™‚é–“ã€ã€Œåœæ­¢ã€åœ¨æª”å°¾å¯«å…¥çµæŸæ™‚é–“  
- ğŸ§µ ä»¥ `threading.Lock` ç¢ºä¿å¤šåŸ·è¡Œç·’å¯«æª”å®‰å…¨

---

## æª”æ¡ˆå·®ç•°ï¼ˆé‡é»ç¯€éŒ„ï¼‰

### `app.py`ï¼ˆå®Œæ•´æ›´æ–°ç‰ˆï¼‰
```python
import os, datetime, threading, queue, time, numpy as np, av, streamlit as st
from dotenv import load_dotenv
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from audio_chunker import Chunker, pcm16_to_wav_bytes
from transcriber import transcribe_wav_bytes

load_dotenv()
st.set_page_config(page_title="å³æ™‚é€å­—ç¨¿ (gpt-4o-mini-transcribe)", layout="centered")
st.title("ğŸ¤ å³æ™‚é€å­—ç¨¿ â€“ gpt-4o-mini-transcribe")
st.caption("æŒ‰ã€Œé–‹å§‹è½‰éŒ„ã€å¾Œä½¿ç”¨ç€è¦½å™¨éº¥å…‹é¢¨ï¼ŒæŒçºŒä»¥ 2 ç§’å°æ®µä¸Šå‚³åˆ° OpenAI è½‰éŒ„ä¸¦å³æ™‚é¡¯ç¤ºï¼›åŒæ™‚å¯«å…¥ ./resource/*.txt")

# --- ç‹€æ…‹åˆå§‹åŒ– ----
if "transcript" not in st.session_state:
    st.session_state.transcript = []
if "running" not in st.session_state:
    st.session_state.running = False
if "audio_q" not in st.session_state:
    st.session_state.audio_q = queue.Queue(maxsize=32)  # éŸ³è¨Š chunk ä½‡åˆ—
if "worker_started" not in st.session_state:
    st.session_state.worker_started = False
if "file_path" not in st.session_state:
    st.session_state.file_path = None
if "file_lock" not in st.session_state:
    st.session_state.file_lock = threading.Lock()

# --- UI æ§åˆ¶ ----
basename = st.text_input("è¼¸å‡ºæª”åï¼ˆ.txtï¼Œè‡ªå‹•ç”Ÿæˆå¯ç•™ç©ºï¼‰", value="")

col1, col2, col3 = st.columns([1,1,2])
with col1:
    if st.button("â–¶ï¸ é–‹å§‹è½‰éŒ„", type="primary"):
        # è¨­å®šè¼¸å‡ºæª”è·¯å¾‘
        os.makedirs("resource", exist_ok=True)
        if basename.strip():
            filename = basename.strip()
            if not filename.endswith(".txt"):
                filename += ".txt"
        else:
            ts = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            filename = f"transcript-{ts}.txt"
        st.session_state.file_path = os.path.join("resource", filename)

        # æª”é ­æ¨™è¨˜
        with st.session_state.file_lock, open(st.session_state.file_path, "a", encoding="utf-8") as f:
            f.write(f"# START {datetime.datetime.now().isoformat()}\n")

        st.session_state.running = True

with col2:
    if st.button("â¹ï¸ åœæ­¢"):
        # æª”å°¾æ¨™è¨˜
        if st.session_state.file_path:
            with st.session_state.file_lock, open(st.session_state.file_path, "a", encoding="utf-8") as f:
                f.write(f"# END   {datetime.datetime.now().isoformat()}\n")
        st.session_state.running = False

chunk_secs = st.slider("ç‰‡æ®µç§’æ•¸", 1.0, 5.0, 2.0, 0.5)
vad_rms    = st.slider("VAD éŸ³é‡é–€æª» (RMS)", 50, 1000, 200, 10)

if st.session_state.file_path:
    st.info(f"å¯«å…¥ä¸­ï¼š`{st.session_state.file_path}`")

placeholder = st.empty()
download_btn = st.empty()

# --- éŸ³è¨Šè™•ç† callback ----
chunker = Chunker(sample_rate=48000, chunk_secs=float(chunk_secs), vad_rms=int(vad_rms))

def audio_frame_callback(frame: av.AudioFrame) -> av.AudioFrame:
    # å–å¾— PCMï¼Œæ··æˆå–®è²é“ int16
    pcm = frame.to_ndarray()
    if pcm.ndim == 2:
        pcm = pcm.mean(axis=0)
    pcm = pcm.astype(np.int16, copy=False)

    # åƒ…åœ¨ running æ™‚æ”¶é›†
    if st.session_state.running:
        chunk = chunker.push(pcm)
        if chunk is not None:
            wav_bytes = pcm16_to_wav_bytes(chunk, sample_rate=48000)
            try:
                st.session_state.audio_q.put_nowait(wav_bytes)
            except queue.Full:
                pass  # å¿½ç•¥æ“å¡ï¼Œé¿å…é˜»å¡éŸ³è¨Šå›èª¿
    return frame

# --- å•Ÿå‹• WebRTC éº¥å…‹é¢¨ ----
rtc_configuration = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})
webrtc_streamer(
    key="mic",
    mode=WebRtcMode.SENDONLY,
    audio_frame_callback=audio_frame_callback,
    media_stream_constraints={"video": False, "audio": True},
    rtc_configuration=rtc_configuration,
)

# --- è½‰éŒ„èƒŒæ™¯åŸ·è¡Œç·’ ----
def worker():
    while True:
        wav_bytes = st.session_state.audio_q.get()
        try:
            text = transcribe_wav_bytes(wav_bytes)
            text = text.strip()
            if text:
                st.session_state.transcript.append(text)
                # ç«‹åˆ»å¯«æª”
                if st.session_state.file_path:
                    with st.session_state.file_lock, open(st.session_state.file_path, "a", encoding="utf-8") as f:
                        f.write(text + "\n")
        except Exception as e:
            st.session_state.transcript.append(f"[ERROR] {e}")
        finally:
            time.sleep(0.01)

if not st.session_state.worker_started:
    threading.Thread(target=worker, daemon=True).start()
    st.session_state.worker_started = True

# --- UI å‘ˆç¾èˆ‡ä¸‹è¼‰ ---
joined = "\n".join(st.session_state.transcript[-400:])  # é¿å…éé•·
placeholder.text_area("é€å­—ç¨¿ï¼ˆå³æ™‚è¿½åŠ ï¼‰", joined, height=320)
if joined:
    download_btn.download_button(
        "ä¸‹è¼‰ç›®å‰é€å­—ç¨¿ (.txt)",
        data=joined.encode("utf-8"),
        file_name="transcript-live.txt",
        mime="text/plain",
        use_container_width=True,
    )
```

---

## æ³¨æ„äº‹é …

- ç›®éŒ„ `resource/` éœ€æœ‰å¯«å…¥æ¬Šé™ï¼ˆDocker æˆ–é›²ç«¯ä¸»æ©Ÿè«‹æ›è¼‰å°æ‡‰ Volume/ç£ç¢Ÿï¼‰ã€‚
- è‹¥å¸Œæœ›æ¯æ¬¡ã€Œé–‹å§‹è½‰éŒ„ã€è¦†è“‹èˆŠæª”ï¼Œå¯å°‡ `"a"` æ”¹ç‚º `"w"`ï¼ˆéœ€è‡ªè¡Œè©•ä¼°å¤šåŸ·è¡Œç·’ï¼‰ã€‚
- å¯åœ¨ `worker()` è£¡åŠ å…¥ç°¡å–®çš„æ®µè½æ™‚é–“æˆ³ï¼ˆä¾‹å¦‚æ¯æ®µå‰åŠ  `datetime`ï¼‰ã€‚
- è‹¥è¦é¿å…æª”åä¸­å‡ºç¾éæ³•å­—å…ƒï¼Œè«‹åœ¨çµ„æª”åæ™‚åšæ¸…ç†ã€‚

---

## ç‰ˆæœ¬æ§åˆ¶èˆ‡éƒ¨ç½²

- å»ºè­°å°‡ `resource/` åˆ—å…¥ `.gitignore`ï¼ˆé¿å…å°‡é€å­—ç¨¿é€²ç‰ˆï¼‰ã€‚
- éƒ¨ç½²åˆ°é›²ç«¯ï¼ˆå¦‚ Streamlit Community / EC2 / Azure App Serviceï¼‰æ™‚ï¼Œè«‹ç¢ºèªå®¹å™¨æˆ–ä¸»æ©Ÿçš„æŒä¹…åŒ–ç­–ç•¥ï¼ˆVolumeï¼‰ã€‚

---

## åƒè€ƒ
- **Audio APIï¼ˆSpeech-to-Text Quickstartï¼‰**ï¼šæ”¯æ´ `gpt-4o(-mini)-transcribe` æ–¼ `/audio/transcriptions`ã€‚îˆ€citeîˆ‚turn0search7îˆ  
- **streamlit-webrtc å®˜æ–¹æ–‡ä»¶**ï¼šç€è¦½å™¨éº¥å…‹é¢¨ä¸²æµåˆ° Pythonã€éŸ³è¨Šå›èª¿ç¤ºä¾‹ã€‚îˆ€citeîˆ‚turn6view0îˆ  
- **Realtime API**ï¼ˆè‹¥è¦æ›´ä½å»¶é²ï¼‰ï¼šå®˜æ–¹æŒ‡å—ã€‚îˆ€citeîˆ‚turn0search6îˆ‚turn0search11îˆ

---

## Commit ç¯„ä¾‹
- `feat(rt-transcribe): mic streaming + chunked transcription via gpt-4o-mini-transcribe`
- `chore: add VAD & rtc config, .env.example, requirements`
- `docs: add PR for real-time mic transcription`
